import{a as i,c as a,d as n,o as l}from"./app-D5tjPIRP.js";const t={};function h(p,s){return l(),a("div",null,[...s[0]||(s[0]=[n(`<p><a href="https://ni3hb10ebs9.feishu.cn/docx/MexDdtomJoA49fx2iuWckQwXnaf?from=from_copylink" target="_blank" rel="noopener noreferrer"> 什么是人工智能？</a></p><h1 id="软件安装及环境配置" tabindex="-1"><a class="header-anchor" href="#软件安装及环境配置"><span>软件安装及环境配置</span></a></h1><blockquote><p><strong>从这开始才是AI-NLP入门指南的主体部分</strong></p></blockquote><ul><li><p><strong>电脑配置</strong>：一般建议有NVIDIA显卡以支持CUDA加速。到NLP部分可以考虑云服务器。</p></li><li><p><strong>软件安装</strong>：</p><ul><li><p><strong>Anaconda or miniconda or uv</strong>：用于包管理和环境配置，简化库的安装。虚拟环境的使用是必不可少的。（个人推荐anaconda，除了内存大没什么缺点）</p></li><li><p><strong>PyCharm / Vscode / Cursor</strong>：开发工具。喜欢哪个用哪个。</p></li><li><p><strong>Python</strong>：建议安装&gt;=3.7版本。</p></li><li><p><strong>vpn: </strong>访问外网会用上。需要连接外网的vpn，如果使用的是实验室的服务器，需要使用校园网or<a href="https://wxb.fzu.edu.cn/info/1011/1191.htm" target="_blank" rel="noopener noreferrer">福大vpn</a></p></li><li><p>可参考<a href="https://www.bilibili.com/video/BV1Vu411Y7gL/?spm_id_from=333.337.search-card.all.click&amp;vd_source=b98cb49910094c6df38524c7abf9ff10" target="_blank" rel="noopener noreferrer">Anaconda安装+PyCharm安装和基本使用，Python编程环境安装</a></p></li><li><p>pycharm如果想用专业版可以申请学生认证，也可以看看pdd（当然pdd里其他工具如XSHELL、XFTP也能用上）</p></li><li><p>建议下载anaconda用国内的镜像下比如<strong>https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/</strong></p></li><li><p><a href="https://blog.csdn.net/xiezhipu/article/details/145638765?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522475a980d3161a0d1e145e2f7a6add706%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&amp;request_id=475a980d3161a0d1e145e2f7a6add706&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-145638765-null-null.142%5Ev102%5Epc_search_result_base3&amp;utm_term=uv&amp;spm=1018.2226.3001.4187" target="_blank" rel="noopener noreferrer">什么是python uv，如何在windows上安装uv，基础的用法有哪些？</a>（uv在开发比较好用）</p></li></ul></li></ul><h1 id="python基础" tabindex="-1"><a class="header-anchor" href="#python基础"><span>Python基础</span></a></h1><h4 id="_1-介绍-要求" tabindex="-1"><a class="header-anchor" href="#_1-介绍-要求"><span><strong>1. 介绍/要求</strong></span></a></h4><p>Python 是深度学习和 NLP 领域最常用的编程语言，学习时需掌握<strong>面向对象编程、数据处理、常见库的使用</strong>等核心技能。</p><ul><li><p><strong>重点掌握面向对象编程（OOP）</strong></p><ul><li><p>学习 <strong>类（class）</strong> 和 <strong>对象（object）</strong> 的概念，掌握如何创建类和对象。</p></li><li><p>重点理解 <strong>类的继承、多态、封装</strong>，以及<strong>类之间的关系（如组合、关联、继承）</strong>。</p></li><li><p>熟悉 <code>__init__</code> 构造方法、类方法 <code>@classmethod</code>、静态方法 <code>@staticmethod</code>、魔法方法 <code>__str__</code> 等。</p></li></ul></li><li><p><strong>基本编程能力</strong></p><ul><li><p>具备编写 Python 代码的基础，包括变量、数据类型、控制流（循环、条件语句）、函数、错误处理（try-except）。</p></li><li><p>了解 Python 的常见数据结构：列表（list）、字典（dict）、集合（set）、元组（tuple），以及它们的操作方法。</p></li><li><p>掌握 Python 内置函数，如 <code>map</code>、<code>filter</code>、<code>zip</code>、<code>enumerate</code>，提高代码效率。</p></li></ul></li><li><p><strong>正则表达式（re 模块）</strong>：在文本处理、NLP 任务中常用。</p></li><li><p><strong>函数式编程</strong>：学习 <code>lambda</code>、<code>map</code>、<code>reduce</code>、<code>filter</code>，提高代码简洁性。</p></li><li><p><strong>模块与包管理</strong></p><ul><li><p>学习如何使用 <code>import</code> 导入 Python 标准库和第三方库。</p></li><li><p>掌握 <code>pip</code> 安装、管理 Python 库，以及虚拟环境 <code>venv</code> 或 <code>conda</code> 的使用。</p></li></ul></li><li><p><strong>爬虫相关内容不用看</strong></p><ul><li><p>学习深度学习和 NLP 任务时，爬虫（如 <code>requests</code>、<code>BeautifulSoup</code>、<code>Scrapy</code>）不是必须的内容。</p></li><li><p>如果感兴趣，可以尝试爬取 NLP 训练数据，比如爬取新闻、社交媒体文本等。</p></li></ul></li></ul><h3 id="学习参考" tabindex="-1"><a class="header-anchor" href="#学习参考"><span>学习参考</span></a></h3><ul><li><p><a href="https://www.runoob.com/" target="_blank" rel="noopener noreferrer">菜鸟教程</a></p></li><li><p><a href="https://space.bilibili.com/37974444" target="_blank" rel="noopener noreferrer">黑马程序员</a></p></li><li><p><a href="https://space.bilibili.com/302417610" target="_blank" rel="noopener noreferrer">尚硅谷</a></p></li><li><p><a href="https://www.bilibili.com/video/BV1c4411e77t/?spm_id_from=333.337.search-card.all.click&amp;vd_source=b98cb49910094c6df38524c7abf9ff10" target="_blank" rel="noopener noreferrer">零基础入门学习Python</a></p></li></ul><h1 id="数据科学入门" tabindex="-1"><a class="header-anchor" href="#数据科学入门"><span>数据科学入门</span></a></h1><h3 id="_1-介绍-要求-1" tabindex="-1"><a class="header-anchor" href="#_1-介绍-要求-1"><span><strong>1. 介绍/要求</strong></span></a></h3><p>在深度学习、NLP 任务以及数据科学竞赛（如 Kaggle，数学建模大赛）中，<strong>数据处理和数据可视化</strong>是至关重要的技能。高质量的数据预处理往往比模型选择更重要，而数据可视化可以帮助我们更好地理解数据、优化模型。</p><hr><h3 id="_2-pandas-数据处理" tabindex="-1"><a class="header-anchor" href="#_2-pandas-数据处理"><span><strong>2. Pandas：数据处理</strong></span></a></h3><p>Pandas 是 Python 最常用的数据分析库，能够高效处理<strong>结构化数据</strong>（如 CSV、Excel、数据库表等）。</p><ul><li><p><strong>学习 DataFrame（数据框）</strong></p><ul><li><p>创建 DataFrame（从字典、列表、NumPy 数组、CSV 文件等创建）。</p></li><li><p>熟悉索引和列操作（<code>df.iloc</code>、<code>df.loc</code>）。</p></li><li><p>进行数据筛选（条件查询、索引操作）。</p></li></ul></li><li><p><strong>数据清洗</strong></p><ul><li><p>处理缺失值（<code>df.fillna()</code> 填充、<code>df.dropna()</code> 删除）。</p></li><li><p>处理重复值（<code>df.duplicated()</code> 检测，<code>df.drop_duplicates()</code> 删除）。</p></li><li><p>数据格式转换（字符串、日期时间转换）。</p></li></ul></li><li><p><strong>数据分组与聚合</strong></p><ul><li><p>使用 <code>groupby()</code> 进行数据分组统计。</p></li><li><p>计算均值、中位数、最大最小值等统计信息。</p></li></ul></li><li><p><strong>数据导入导出</strong></p><ul><li><p>读取和保存 CSV、JSON 文件（<code>pd.read_csv()</code>，<code>df.to_csv()</code>）。</p></li><li><p>处理 Excel（<code>pd.read_excel()</code>）。</p></li></ul></li></ul><hr><h3 id="_3-numpy-数值计算" tabindex="-1"><a class="header-anchor" href="#_3-numpy-数值计算"><span><strong>3. NumPy：数值计算</strong></span></a></h3><p>NumPy 是<strong>处理大规模数组和矩阵计算</strong>的核心库，在深度学习和 NLP 任务中，很多数据处理都需要 NumPy 操作。</p><ul><li><p><strong>NumPy 数组（ndarray）</strong></p><ul><li><p>创建数组（<code>np.array()</code>、<code>np.zeros()</code>、<code>np.ones()</code>、<code>np.arange()</code>）。</p></li><li><p>索引、切片（类似于 Python 列表，但更高效）。</p></li><li><p>生成随机数，例如： </p></li></ul><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-python"><span class="line"><span style="--shiki-light:#1E754F;--shiki-dark:#4D9375;">import</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> numpy </span><span style="--shiki-light:#1E754F;--shiki-dark:#4D9375;">as</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> np</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">np</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">random</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">randint</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;">1</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;"> 100</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span><span style="--shiki-light:#B07D48;--shiki-dark:#BD976A;"> size</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;">100</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">)</span><span style="--shiki-light:#A0ADA0;--shiki-dark:#758575DD;">  # 生成 100 个 1-100 之间的随机整数</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div></li><li><p><strong>数学函数</strong></p><ul><li><p>线性代数运算（<code>np.dot()</code> 矩阵乘法、<code>np.linalg.inv()</code> 逆矩阵）。</p></li><li><p>统计函数（<code>np.mean()</code>、<code>np.std()</code>、<code>np.median()</code>）。</p></li><li><p>广播机制：在不同形状的数组之间进行运算。</p></li></ul></li></ul><hr><h3 id="_4-matplotlib-与-seaborn-数据可视化" tabindex="-1"><a class="header-anchor" href="#_4-matplotlib-与-seaborn-数据可视化"><span><strong>4. Matplotlib 与 Seaborn：数据可视化</strong></span></a></h3><p>数据可视化是理解数据、调试模型的重要工具。</p><h4 id="_4-1-matplotlib" tabindex="-1"><a class="header-anchor" href="#_4-1-matplotlib"><span><strong>4.1 Matplotlib</strong></span></a></h4><p>Matplotlib 是 Python 最基础的绘图库，可以用于创建多种图表：</p><ul><li><p><strong>学习基本绘图</strong></p><p> 包括且不限于：</p><ul><li><p>折线图（<code>plt.plot()</code>）</p></li><li><p>柱状图（<code>plt.bar()</code>）</p></li><li><p>散点图（<code>plt.scatter()</code>）</p></li><li><p>直方图（<code>plt.hist()</code>）</p></li></ul></li><li><p><strong>可视化自定义</strong></p><ul><li><p>设置标题、坐标轴标签、图例。</p></li><li><p>自定义颜色、样式、网格线。</p></li></ul></li></ul><h4 id="_4-2-seaborn" tabindex="-1"><a class="header-anchor" href="#_4-2-seaborn"><span><strong>4.2 Seaborn</strong></span></a></h4><p>Seaborn 在 Matplotlib 基础上进行了优化，提供更<strong>美观、简洁</strong>的统计图形：</p><ul><li><p><strong>常见图表</strong></p><ul><li><p>分布图（<code>sns.histplot()</code>、<code>sns.kdeplot()</code>）。</p></li><li><p>盒须图（<code>sns.boxplot()</code>）—— 可视化数据分布及异常值。</p></li><li><p>热力图（<code>sns.heatmap()</code>）—— 适用于相关性分析。</p></li></ul></li><li><p><strong>风格调整</strong></p><ul><li><p>设置主题（<code>sns.set_theme()</code>）。</p></li><li><p>组合多个图表（如 <code>sns.pairplot()</code> 进行数据探索）。</p></li></ul></li></ul><h3 id="学习参考-1" tabindex="-1"><a class="header-anchor" href="#学习参考-1"><span>学习参考</span></a></h3><ul><li><p>同上文。</p></li><li><p>也可以把文档复制粘贴给gpt让他教你</p></li></ul><h1 id="pytorch基础" tabindex="-1"><a class="header-anchor" href="#pytorch基础"><span>PyTorch基础</span></a></h1><p><strong>介绍/要求</strong></p><p>PyTorch 是当前主流的深度学习框架之一，具有 <strong>动态图计算</strong>、<strong>易调试</strong>、<strong>强大的 GPU 支持</strong> 等优点，被广泛用于计算机视觉（CV）、自然语言处理（NLP）等领域。 <strong>建议学习阶段使用 PyTorch 版本低于 2.0（尤其是想学CV的）</strong>，因为学习过程中可能会遇到 <strong>老代码与 2.0 版本不兼容的问题</strong>。当然，随着学习进度的推进，也要创建相应的环境，比如到大语言模型阶段，一般都常驻在2.0以上。</p><h3 id="第一阶段-pytorch-基础" tabindex="-1"><a class="header-anchor" href="#第一阶段-pytorch-基础"><span><strong>第一阶段：PyTorch 基础</strong></span></a></h3><h4 id="_1-张量-tensor-操作" tabindex="-1"><a class="header-anchor" href="#_1-张量-tensor-操作"><span><strong>（1） 张量（Tensor）操作</strong></span></a></h4><ul><li><p>张量是 PyTorch 的核心数据结构，类似于 NumPy 的多维数组，但支持 GPU 加速计算。</p></li><li><p>需要掌握的操作包括 <strong>张量的创建、索引、切片、变形、运算</strong> 等。</p></li><li><p>重点理解 <strong>如何获取张量的转置</strong> 以及 <strong>如何改变张量的形状</strong>，这些操作在构建深度学习模型时非常常见。</p></li></ul><h4 id="_2-torchvision-transforms-进行数据预处理" tabindex="-1"><a class="header-anchor" href="#_2-torchvision-transforms-进行数据预处理"><span><strong>（2） torchvision.transforms 进行数据预处理</strong></span></a></h4><ul><li><p><code>torchvision.transforms</code> 是 PyTorch 处理 <strong>图像数据</strong> 的重要工具，常用于数据增强和预处理。</p></li><li><p>关键操作包括 <strong>调整尺寸、归一化、随机翻转</strong> 等，以提高模型的泛化能力。</p></li></ul><h4 id="_3-dataset-与-dataloader" tabindex="-1"><a class="header-anchor" href="#_3-dataset-与-dataloader"><span><strong>（3） Dataset 与 Dataloader</strong></span></a></h4><ul><li><p>PyTorch 通过 <code>Dataset</code> 和 <code>Dataloader</code> 进行数据加载和批量处理，提供 <strong>自动化的数据迭代机制</strong>，可以高效地训练神经网络。</p></li><li><p>需要掌握如何 <strong>自定义 Dataset</strong>，并进行 <strong>数据预处理</strong> 和 <strong>批量加载</strong>。</p></li></ul><p>比如</p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-python"><span class="line"><span style="--shiki-light:#1E754F;--shiki-dark:#4D9375;">from</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> torch</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">utils</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">data </span><span style="--shiki-light:#1E754F;--shiki-dark:#4D9375;">import</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> Dataset</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> DataLoader</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#AB5959;--shiki-dark:#CB7676;">class</span><span style="--shiki-light:#2E8F82;--shiki-dark:#5DA994;"> CustomDataset</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">Dataset</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">):</span></span>
<span class="line"><span style="--shiki-light:#AB5959;--shiki-dark:#CB7676;">    def</span><span style="--shiki-light:#998418;--shiki-dark:#B8A965;"> __init__</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">self</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> data</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> labels</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">):</span></span>
<span class="line"><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;">        self</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">data </span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> data</span></span>
<span class="line"><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;">        self</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">labels </span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> labels</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#AB5959;--shiki-dark:#CB7676;">    def</span><span style="--shiki-light:#998418;--shiki-dark:#B8A965;"> __len__</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">self</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">):</span></span>
<span class="line"><span style="--shiki-light:#1E754F;--shiki-dark:#4D9375;">        return</span><span style="--shiki-light:#998418;--shiki-dark:#B8A965;"> len</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;">self</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">data</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#AB5959;--shiki-dark:#CB7676;">    def</span><span style="--shiki-light:#998418;--shiki-dark:#B8A965;"> __getitem__</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">self</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> idx</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">):</span></span>
<span class="line"><span style="--shiki-light:#1E754F;--shiki-dark:#4D9375;">        return</span><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;"> self</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">data</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">[</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">idx</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">],</span><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;"> self</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">labels</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">[</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">idx</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">]</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0ADA0;--shiki-dark:#758575DD;"># 生成数据</span></span>
<span class="line"><span style="--shiki-light:#1E754F;--shiki-dark:#4D9375;">import</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> torch</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">X </span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> torch</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">randn</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;">100</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;"> 10</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">)</span><span style="--shiki-light:#A0ADA0;--shiki-dark:#758575DD;">  # 100 个样本，每个样本 10 维</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">y </span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> torch</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">randint</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;">0</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;"> 2</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span><span style="--shiki-light:#999999;--shiki-dark:#666666;"> (</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;">100</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,))</span><span style="--shiki-light:#A0ADA0;--shiki-dark:#758575DD;">  # 100 个二分类标签</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">dataset </span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> CustomDataset</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">X</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> y</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">)</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">dataloader </span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> DataLoader</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">dataset</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span><span style="--shiki-light:#B07D48;--shiki-dark:#BD976A;"> batch_size</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;">32</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span><span style="--shiki-light:#B07D48;--shiki-dark:#BD976A;"> shuffle</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#1E754F;--shiki-dark:#4D9375;">True</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#1E754F;--shiki-dark:#4D9375;">for</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> batch_X</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> batch_y </span><span style="--shiki-light:#1E754F;--shiki-dark:#4D9375;">in</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> dataloader</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">:</span></span>
<span class="line"><span style="--shiki-light:#998418;--shiki-dark:#B8A965;">    print</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">batch_X</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">shape</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> batch_y</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">shape</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">)</span><span style="--shiki-light:#A0ADA0;--shiki-dark:#758575DD;">  # 输出 (32,10) (32,)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="_4-torch-device" tabindex="-1"><a class="header-anchor" href="#_4-torch-device"><span><strong>（4） torch.device</strong></span></a></h4><ul><li><p>PyTorch 允许使用 <strong>GPU 加速计算</strong>，可以通过 <code>torch.device</code> 在 <strong>CPU 和 GPU 之间切换</strong>。</p></li><li><p>了解如何 <strong>将数据和模型放置到指定设备</strong>，优化训练效率。</p></li></ul><p>比如</p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-python"><span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">device </span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> torch</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">device</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">cuda</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#1E754F;--shiki-dark:#4D9375;"> if</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> torch</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">cuda</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">is_available</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">()</span><span style="--shiki-light:#1E754F;--shiki-dark:#4D9375;"> else</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;"> &quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">cpu</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">)</span></span>
<span class="line"><span style="--shiki-light:#998418;--shiki-dark:#B8A965;">print</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">Using device:</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> device</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">)</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">model </span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> MyModel</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">().</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">to</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">device</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">)</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">inputs</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> labels </span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> inputs</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">to</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">device</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">),</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> labels</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">to</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">device</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="_5-多层感知机-mlp" tabindex="-1"><a class="header-anchor" href="#_5-多层感知机-mlp"><span><strong>（5） 多层感知机（MLP）</strong></span></a></h4><ul><li><p>多层感知机（MLP）是最基础的神经网络结构，由 <strong>输入层、隐藏层、输出层</strong> 组成。</p></li><li><p>需要理解 <strong>前向传播（Forward Propagation）</strong> 和 <strong>反向传播（Backward Propagation）</strong> 计算过程，以及如何通过 <strong>激活函数</strong> 使模型具备非线性表达能力。</p></li></ul><p>比如</p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-python"><span class="line"><span style="--shiki-light:#1E754F;--shiki-dark:#4D9375;">import</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> torch</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">nn </span><span style="--shiki-light:#1E754F;--shiki-dark:#4D9375;">as</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> nn</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#AB5959;--shiki-dark:#CB7676;">class</span><span style="--shiki-light:#2E8F82;--shiki-dark:#5DA994;"> MLP</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">nn</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">Module</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">):</span></span>
<span class="line"><span style="--shiki-light:#AB5959;--shiki-dark:#CB7676;">    def</span><span style="--shiki-light:#998418;--shiki-dark:#B8A965;"> __init__</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">self</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> input_dim</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> hidden_dim</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> output_dim</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">):</span></span>
<span class="line"><span style="--shiki-light:#998418;--shiki-dark:#B8A965;">        super</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;">MLP</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;"> self</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">).</span><span style="--shiki-light:#998418;--shiki-dark:#B8A965;">__init__</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">()</span></span>
<span class="line"><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;">        self</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">fc1 </span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> nn</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">Linear</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">input_dim</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> hidden_dim</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">)</span></span>
<span class="line"><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;">        self</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">relu </span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> nn</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">ReLU</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">()</span></span>
<span class="line"><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;">        self</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">fc2 </span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> nn</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">Linear</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">hidden_dim</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> output_dim</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#AB5959;--shiki-dark:#CB7676;">    def</span><span style="--shiki-light:#59873A;--shiki-dark:#80A665;"> forward</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">self</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> x</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">):</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">        x </span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;"> self</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">relu</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;">self</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">fc1</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">x</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">))</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">        x </span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;"> self</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">fc2</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">x</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">)</span></span>
<span class="line"><span style="--shiki-light:#1E754F;--shiki-dark:#4D9375;">        return</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> x</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">model </span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> MLP</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#B07D48;--shiki-dark:#BD976A;">input_dim</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;">10</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span><span style="--shiki-light:#B07D48;--shiki-dark:#BD976A;"> hidden_dim</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;">32</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span><span style="--shiki-light:#B07D48;--shiki-dark:#BD976A;"> output_dim</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;">2</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="_6-损失函数与优化器" tabindex="-1"><a class="header-anchor" href="#_6-损失函数与优化器"><span><strong>（6） 损失函数与优化器</strong></span></a></h4><ul><li><p><strong>损失函数</strong> 用于衡量模型的预测结果与真实值的误差，不同任务使用不同的损失函数： </p><ul><li><p><strong>MSELoss</strong>：用于回归任务，计算均方误差。</p></li><li><p><strong>CrossEntropyLoss</strong>：用于分类任务，衡量预测类别的交叉熵损失。</p></li></ul></li><li><p><strong>优化器</strong> 用于更新模型参数： </p><ul><li><p><strong>SGD（随机梯度下降）</strong>：计算简单，但可能收敛较慢。</p></li><li><p><strong>Adam（自适应优化）</strong>：能够自动调整学习率，提高训练速度。</p></li></ul></li></ul><h4 id="_7-正则化" tabindex="-1"><a class="header-anchor" href="#_7-正则化"><span><strong>（7） 正则化</strong></span></a></h4><ul><li><p>正则化用于防止模型 <strong>过拟合</strong>，提升泛化能力。</p></li><li><p>主要包括： </p><ul><li><p><strong>L1 正则化</strong>：鼓励参数稀疏，适用于特征选择任务。</p></li><li><p><strong>L2 正则化</strong>（权重衰减）：防止模型参数过大，提高模型的稳定性。</p></li></ul></li></ul><h4 id="_8-模型保存与加载" tabindex="-1"><a class="header-anchor" href="#_8-模型保存与加载"><span><strong>（8） 模型保存与加载</strong></span></a></h4><ul><li><p>在训练深度学习模型时，需要掌握 <strong>如何保存训练好的模型</strong> 以及 <strong>如何加载模型进行推理或继续训练</strong>。</p></li><li><p>训练好的模型可以用于 <strong>迁移学习、模型部署</strong> 等任务。</p></li></ul><p>比如</p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-python"><span class="line"><span style="--shiki-light:#A0ADA0;--shiki-dark:#758575DD;">#保存模型： </span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">torch</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">save</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">model</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">state_dict</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(),</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;"> &quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">model.pth</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">)</span></span>
<span class="line"><span style="--shiki-light:#A0ADA0;--shiki-dark:#758575DD;">#加载模型： </span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">model</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">load_state_dict</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">torch</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">load</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">model.pth</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">))</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><hr><h3 id="第二阶段-深入-pytorch" tabindex="-1"><a class="header-anchor" href="#第二阶段-深入-pytorch"><span><strong>第二阶段：深入 PyTorch</strong></span></a></h3><h4 id="_1-卷积神经网络-cnn" tabindex="-1"><a class="header-anchor" href="#_1-卷积神经网络-cnn"><span><strong>（1） 卷积神经网络（CNN）</strong></span></a></h4><ul><li><p>CNN 是计算机视觉任务中最重要的模型之一，其核心机制包括 <strong>卷积层、池化层、激活函数</strong>。</p></li><li><p>需要理解 <strong>卷积操作的原理</strong>，以及 <strong>如何通过卷积核提取图像特征</strong>。</p></li><li><p>了解经典 CNN 结构，如 <strong>VGG、ResNet</strong>，并理解它们的改进点。</p></li></ul><h4 id="_2-循环神经网络-rnn" tabindex="-1"><a class="header-anchor" href="#_2-循环神经网络-rnn"><span><strong>（2） 循环神经网络（RNN）</strong></span></a></h4><ul><li><p>RNN 适用于处理 <strong>序列数据</strong>（如文本、时间序列），其核心思想是通过 <strong>隐藏状态（Hidden State）</strong> 传递信息。</p></li><li><p>需要理解： </p><ul><li><p><strong>RNN 处理序列数据的方式</strong>，如何通过时间步（Time Step）传递信息。</p></li><li><p><strong>LSTM（长短时记忆网络）</strong> 解决长序列依赖问题。</p></li><li><p><strong>GRU（门控循环单元）</strong> 作为 LSTM 的简化版本，在某些任务上能提供相似性能但计算成本更低。</p></li></ul></li></ul><h3 id="学习参考-2" tabindex="-1"><a class="header-anchor" href="#学习参考-2"><span>学习参考</span></a></h3><ul><li><p><a href="https://www.bilibili.com/video/BV1hE411t7RN/?spm_id_from=333.999.0.0" target="_blank" rel="noopener noreferrer">小土堆</a>（基础入门）</p></li><li><p><a href="https://space.bilibili.com/1567748478" target="_blank" rel="noopener noreferrer">李沐--动手学深度学习</a>（注意的是，不要过度依赖d2l库，因为正常来说不会使用这个的）</p></li><li><p>吴恩达深度学习课程（原理）</p></li><li><p>花书（《Deep Learning》）</p></li><li><p><a href="https://space.bilibili.com/3546620985608836/video" target="_blank" rel="noopener noreferrer">StatQuest</a>（原理）</p></li><li><p><a href="https://datawhalechina.github.io/thorough-pytorch/" target="_blank" rel="noopener noreferrer">深入浅出PyTorch</a></p></li></ul><h1 id="自然语言处理-nlp-natural-language-processing" tabindex="-1"><a class="header-anchor" href="#自然语言处理-nlp-natural-language-processing"><span>自然语言处理（NLP, Natural Language Processing）</span></a></h1><p><strong>这个章节以后的所有内容其实都是关于NLP的，层级关系是这样的：</strong></p><p><strong>NLP（自然语言处理）</strong></p><p><strong> ├── PLM（预训练语言模型，如 BERT, GPT, T5）</strong></p><p><strong> ├── LLM（大语言模型，如 GPT-4, LLaMA, ChatGLM）</strong></p><ul><li><p>NLP 是最广泛的概念，包含所有涉及文本处理的任务。</p></li><li><p>PLM 是 NLP 任务中的核心技术，通过预训练学习通用语言知识，提升下游任务性能。</p></li><li><p>LLM 是 PLM 的扩展，通过 超大规模参数+海量数据训练，在没有额外微调的情况下也能完成复杂 NLP 任务。</p></li></ul><p><strong>自然语言处理（Natural Language Processing, NLP）</strong> 是人工智能（AI）领域的重要分支，旨在让计算机能够理解、生成和处理人类语言。NLP 涉及多个核心任务，如<strong>文本分类、机器翻译、情感分析、命名实体识别、问答系统</strong>等，广泛应用于搜索引擎、智能助手、自动摘要等场景。</p><ol><li><strong>要求</strong></li></ol><ul><li><p>重点掌握 NLP 的核心概念和主要模型，尤其是 <strong>词嵌入、Seq2Seq、注意力机制、Transformer</strong> 这些基础内容。</p></li><li><p>逐步掌握 <strong>深度学习在 NLP 任务中的应用</strong>，包括文本分类、机器翻译、文本生成等任务。</p></li></ul><ul><li><strong>重点内容</strong></li></ul><h4 id="_1-词嵌入技术" tabindex="-1"><a class="header-anchor" href="#_1-词嵌入技术"><span><strong>（1）词嵌入技术</strong></span></a></h4><ul><li><p>了解 <strong>Word2Vec、GloVe</strong> 等模型，掌握词向量的生成及其应用。</p></li><li><p>重点理解<strong>词向量的计算原理（如 Skip-gram, CBOW）</strong>。</p></li><li><p>仅需了解，不要求深入实现。</p></li></ul><h4 id="_2-seq2seq-序列到序列模型" tabindex="-1"><a class="header-anchor" href="#_2-seq2seq-序列到序列模型"><span><strong>（2）Seq2Seq（序列到序列模型）</strong></span></a></h4><ul><li><p>了解 <strong>如何处理序列到序列的任务</strong>，如 <strong>机器翻译、文本摘要</strong>。</p></li><li><p>了解 <strong>编码器-解码器（Encoder-Decoder）结构</strong>，包括 RNN、LSTM 版本的 Seq2Seq。</p></li><li><p>可尝试基于 PyTorch复现简单的 Seq2Seq 模型。</p></li></ul><h4 id="_3-注意力机制-attention" tabindex="-1"><a class="header-anchor" href="#_3-注意力机制-attention"><span><strong>（3）注意力机制（Attention）</strong></span></a></h4><ul><li><p>学习 <strong>Attention 机制</strong>，理解其数学公式与实现： </p><ul><li><p><strong>Self-Attention 公式</strong>： $\${Attention}(Q, K, V) = \\text{softmax} \\left( \\frac{QK^T}{\\sqrt{d_k}} \\right) $$</p></li><li><p><strong>Multi-Head Attention</strong> 的作用及实现。</p></li></ul></li><li><p>重点理解 <strong>Transformer</strong> 如何利用 Self-Attention。</p></li></ul><h4 id="_4-transformer-架构" tabindex="-1"><a class="header-anchor" href="#_4-transformer-架构"><span><strong>（4）Transformer 架构</strong></span></a></h4><ul><li><p>理解 Transformer 结构，明确： </p><ul><li><p><strong>Encoder 作用</strong>（提取输入特征）。</p></li><li><p><strong>Decoder 作用</strong>（生成输出序列）。</p></li></ul></li><li><p><strong>尝试复现 Attention Layer</strong>（如果能手写一个 Attention Layer，会有更深刻的理解）。</p></li></ul><ul><li><strong>学习参考</strong></li></ul><ul><li><p>李沐 NLP 课程</p></li><li><p>HuggingFace 官方教程</p></li><li><p>GitHub（多阅读 Transformer 相关模型的源码）</p></li><li><p>谷歌学术</p></li></ul><h1 id="预训练模型-plm-pre-trained-language-model" tabindex="-1"><a class="header-anchor" href="#预训练模型-plm-pre-trained-language-model"><span>预训练模型（PLM, Pre-trained Language Model）</span></a></h1><h4 id="_1-介绍-要求-2" tabindex="-1"><a class="header-anchor" href="#_1-介绍-要求-2"><span><strong>1. 介绍/要求</strong></span></a></h4><ul><li><p><strong>学习目标</strong>：深入理解 <strong>预训练语言模型（PLM, Pre-trained Language Model）</strong>，包括 <strong>BERT、GPT、T5、XLNet</strong> 等，掌握其训练方式和应用场景。</p></li><li><p><strong>重点内容</strong>： </p><ul><li><p><strong>自监督学习（Self-Supervised Learning）</strong>：了解 NLP 预训练模型如何通过自监督任务学习表示。</p></li><li><p><strong>自编码（Autoencoding） vs. 自回归（Autoregressive）</strong>：理解不同的预训练范式及其优缺点。</p></li><li><p><strong>不同预训练模型的掩码策略</strong>：对比 BERT、GPT、T5、XLNet、UniLM等模型的掩码机制。</p></li><li><p><strong>Tokenizer 机制</strong>：如何将文本转换为模型可理解的输入。</p></li><li><p><strong>Transformer 在预训练模型中的应用</strong>：掌握 <strong>Attention、Layer Normalization、Residual Connection</strong> 等关键技术。</p></li></ul></li></ul><hr><h4 id="_2-重点内容" tabindex="-1"><a class="header-anchor" href="#_2-重点内容"><span><strong>2. 重点内容</strong></span></a></h4><h5 id="_1-自监督学习-self-supervised-learning" tabindex="-1"><a class="header-anchor" href="#_1-自监督学习-self-supervised-learning"><span><strong>（1） 自监督学习（Self-Supervised Learning）</strong></span></a></h5><ul><li><p><strong>什么是自监督学习？</strong></p><ul><li><p>自监督学习是一种 <strong>无需人工标注</strong> 的学习方式，模型通过自身生成监督信号进行训练。</p></li><li><p>主要用于 <strong>大规模文本数据预训练</strong>，在无监督数据上学习有效的文本表示。</p></li></ul></li><li><p><strong>自监督任务分类</strong>： </p><ul><li><p><strong>自编码（Autoencoding）任务</strong>（如 BERT）</p></li><li><p><strong>自回归（Autoregressive）任务</strong>（如 GPT）</p></li><li><p><strong>对比学习（Contrastive Learning）任务</strong>（如 SimCSE）</p></li></ul></li></ul><h5 id="_2-自编码-vs-自回归" tabindex="-1"><a class="header-anchor" href="#_2-自编码-vs-自回归"><span><strong>（2） 自编码 vs. 自回归</strong></span></a></h5><h5 id="_3-不同的预训练模型的掩码策略" tabindex="-1"><a class="header-anchor" href="#_3-不同的预训练模型的掩码策略"><span><strong>（3） 不同的预训练模型的掩码策略</strong></span></a></h5><ul><li><p><strong>BERT（Bidirectional Encoder Representations from Transformers）</strong></p><ul><li><p><strong>掩码机制</strong>： </p><ul><li><p><strong>MLM（Masked Language Model）</strong>：在输入文本中随机选择 15% 的 Token 进行 Mask，模型需要预测被遮挡的 Token。</p></li><li><p><strong>NSP（Next Sentence Prediction）</strong>：判断两句话是否在原文中相邻（BERT 原始版本使用，但 RoBERTa 取消）。</p></li></ul></li><li><p><strong>优点</strong>：双向编码，可用于文本理解任务。</p></li><li><p><strong>缺点</strong>：不适用于生成任务。</p></li></ul></li><li><p><strong>GPT（Generative Pre-trained Transformer）</strong></p><ul><li><p><strong>掩码机制</strong>： </p><ul><li><strong>Causal Masking（因果遮蔽）</strong>：只能看到之前的 Token，避免模型窥探未来信息。</li></ul></li><li><p><strong>优点</strong>：适用于生成任务（如对话生成、代码生成）。</p></li><li><p><strong>缺点</strong>：单向编码，无法建模完整上下文。</p></li></ul></li><li><p><strong>T5（Text-to-Text Transfer Transformer）</strong></p><ul><li><p><strong>掩码机制</strong>： </p><ul><li><strong>Span Masking（片段遮蔽）</strong>：随机遮蔽文本片段，而不是单个 Token，提高模型对文本片段的理解能力。</li></ul></li><li><p><strong>优点</strong>：适用于 <strong>文本转换任务（翻译、摘要、问答）</strong>。</p></li><li><p><strong>缺点</strong>：训练成本高。</p></li></ul></li><li><p><strong>XLNet（Generalized Autoregressive Pretraining）</strong></p><ul><li><p><strong>掩码机制</strong>： </p><ul><li><strong>Permutation Language Model（排列语言模型）</strong>：通过随机排列 Token 的顺序，使模型学习更全面的上下文信息。</li></ul></li><li><p><strong>优点</strong>：兼具 BERT 的双向性和 GPT 的自回归特性。</p></li><li><p><strong>缺点</strong>：计算开销大，实际应用较少。</p></li></ul></li></ul><h5 id="_4-tokenizer-机制" tabindex="-1"><a class="header-anchor" href="#_4-tokenizer-机制"><span><strong>（4） Tokenizer 机制</strong></span></a></h5><ul><li><p><strong>作用</strong>：将自然语言转换为 Token ID 序列，使 Transformer 能够处理文本。</p></li><li><p><strong>常见 Tokenizer 类型</strong>： </p><ul><li><p><strong>WordPiece（BERT 使用）</strong>：基于子词单元拆分。</p></li><li><p><strong>Byte-Pair Encoding（BPE, GPT 使用）</strong>：基于统计规律合并最常见的字符对。</p></li><li><p><strong>SentencePiece（T5, XLNet 使用）</strong>：无需分词表，适用于多语言任务。</p></li></ul></li></ul><h5 id="_5-layer-normalization-ln-vs-batch-normalization-bn" tabindex="-1"><a class="header-anchor" href="#_5-layer-normalization-ln-vs-batch-normalization-bn"><span><strong>（5） Layer Normalization（LN） vs. Batch Normalization（BN）</strong></span></a></h5><p><strong>Batch Normalization（BN）</strong> 是针对 <strong>整个 mini-batch</strong> 进行归一化，即在 <strong>批次维度</strong> 计算均值和方差，对数据进行标准化。BN 依赖 <strong>批次大小</strong>，在不同 batch 之间共享统计信息，因此在小 batch 训练时效果可能不稳定。BN 主要用于 <strong>CNN（卷积神经网络）</strong>，能够加速训练并减少梯度消失。</p><p><strong>Layer Normalization（LN）</strong> 是针对 <strong>单个样本的特征维度</strong> 进行归一化，即在 <strong>特征维度</strong> 计算均值和方差，使得归一化过程独立于 batch 大小。LN 适用于 <strong>NLP（自然语言处理）</strong> 任务，尤其是 <strong>Transformer</strong> 结构，它不受 batch 变化的影响，因此在 <strong>RNN、Transformer</strong> 等序列模型中表现更稳定。</p><hr><h4 id="_3-学习参考" tabindex="-1"><a class="header-anchor" href="#_3-学习参考"><span><strong>3. 学习参考</strong></span></a></h4><ul><li><p><strong>HuggingFace 官方教程</strong></p></li><li><p><strong>GitHub（Transformer 相关源码）</strong></p></li><li><p><strong>Datawhale 开源 NLP 课程</strong></p></li><li><p><strong>BERT、GPT、T5、XLNet、ELECTRA 论文</strong></p></li></ul><hr><h3 id="总结" tabindex="-1"><a class="header-anchor" href="#总结"><span><strong>总结</strong></span></a></h3><ul><li><p><strong>理解自监督学习（Self-Supervised Learning）如何用于 NLP 预训练</strong>。</p></li><li><p><strong>掌握自编码（BERT）和自回归（GPT）的区别</strong>，理解 Encoder、Decoder 结构。</p></li><li><p><strong>学习不同预训练模型的掩码机制（Masking Strategies）</strong>。</p></li><li><p><strong>理解 Transformer 结构及其在 NLP 任务中的应用</strong>。</p></li></ul><h3 id="学习参考-3" tabindex="-1"><a class="header-anchor" href="#学习参考-3"><span>学习参考</span></a></h3><ul><li><p><a href="https://huggingface.co/" target="_blank" rel="noopener noreferrer">huggingface</a></p></li><li><p><a href="https://github.com/datawhalechina" target="_blank" rel="noopener noreferrer">开源社区datawhale</a></p></li></ul><h1 id="大语言模型-llm-large-language-model" tabindex="-1"><a class="header-anchor" href="#大语言模型-llm-large-language-model"><span>大语言模型（LLM, Large Language Model ）</span></a></h1><p><strong>大语言模型（LLM）</strong>是基于深度学习和Transformer架构的强大自然语言处理工具，能够理解和生成各种类型的文本。它们通过在大规模文本数据上进行预训练，具备强大的语言理解、推理和生成能力。LLM的特点包括大规模的预训练、迁移学习、灵活适应多任务能力、以及出色的文本生成和上下文理解能力。</p><p><strong>部署：</strong></p><p>大模型的显存占用大，学会大模型部署到服务器上，比如autodl。</p><p><strong>使用：</strong></p><p>一般采用的是transformer库和peft库，模型一般在<a href="https://huggingface.co/models?library=pytorch" target="_blank" rel="noopener noreferrer">huggingface</a>里。</p><p>以下是一个简单的模型使用方法:</p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-python"><span class="line"><span style="--shiki-light:#1E754F;--shiki-dark:#4D9375;">import</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> transformers</span></span>
<span class="line"><span style="--shiki-light:#1E754F;--shiki-dark:#4D9375;">import</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> torch</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">model_id </span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;"> &quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">meta-llama/Meta-Llama-3.1-8B-Instruct</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">pipeline </span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> transformers</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">pipeline</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">text-generation</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span></span>
<span class="line"><span style="--shiki-light:#B07D48;--shiki-dark:#BD976A;">    model</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">model_id</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span></span>
<span class="line"><span style="--shiki-light:#B07D48;--shiki-dark:#BD976A;">    model_kwargs</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">={</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">torch_dtype</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">:</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> torch</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">bfloat16</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">},</span></span>
<span class="line"><span style="--shiki-light:#B07D48;--shiki-dark:#BD976A;">    device_map</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">auto</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span></span>
<span class="line"><span style="--shiki-light:#999999;--shiki-dark:#666666;">)</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">messages </span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#999999;--shiki-dark:#666666;"> [</span></span>
<span class="line"><span style="--shiki-light:#999999;--shiki-dark:#666666;">    {</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">role</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">:</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;"> &quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">system</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;"> &quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">content</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">:</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;"> &quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">You are a pirate chatbot who always responds in pirate speak!</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">},</span></span>
<span class="line"><span style="--shiki-light:#999999;--shiki-dark:#666666;">    {</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">role</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">:</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;"> &quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">user</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;"> &quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">content</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">:</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;"> &quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">Who are you?</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">},</span></span>
<span class="line"><span style="--shiki-light:#999999;--shiki-dark:#666666;">]</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">outputs </span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> pipeline</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">    messages</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span></span>
<span class="line"><span style="--shiki-light:#B07D48;--shiki-dark:#BD976A;">    max_new_tokens</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;">256</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span></span>
<span class="line"><span style="--shiki-light:#999999;--shiki-dark:#666666;">)</span></span>
<span class="line"><span style="--shiki-light:#998418;--shiki-dark:#B8A965;">print</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">outputs</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">[</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;">0</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">][</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">generated_text</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">][</span><span style="--shiki-light:#AB5959;--shiki-dark:#CB7676;">-</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;">1</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">])</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>模型的使用相对是比较简单的，难的是对于模型源码和原理的理解</p><p><strong>从经典的Llama开始学习：</strong></p><p>1. <strong>LoRA（低秩适配）</strong></p><ul><li><p><strong>目标</strong>：理解LoRA技术的原理和应用，学习如何通过低秩矩阵减少大模型的计算和存储需求。</p></li><li><p><strong>学习内容</strong>：</p><ul><li><p><strong>LoRA原理</strong>：深入理解LoRA如何通过引入低秩矩阵来减少需要更新的参数数量，同时保持微调效果。</p></li><li><p><strong>LoRA与其他微调方法的对比</strong>：了解LoRA与传统微调方法（如全量微调、Adapter、Prompt Tuning等）的优缺点。</p></li></ul></li></ul><p>2. <strong>梯度检查点（Gradient Checkpointing）</strong></p><ul><li><p><strong>目标</strong>：掌握梯度检查点技术，通过减少内存占用来提升大模型训练的效率。</p></li><li><p><strong>学习内容</strong>：</p><ul><li><strong>梯度检查点概念</strong>：理解梯度检查点的基本原理：通过选择性地保存中间激活值来减少内存占用，而在反向传播时重新计算这些激活。</li></ul></li></ul><p>3. <strong>RoPE（旋转位置编码）</strong></p><ul><li><p><strong>目标</strong>：理解RoPE技术，掌握其在自注意力机制中的应用，尤其是针对长序列建模的优化。</p></li><li><p><strong>学习内容</strong>：</p><ul><li><p><strong>位置编码的作用</strong>：复习Transformer中的标准位置编码（Sinusoidal Position Encoding）的工作原理和局限性。尤其是和BERT的绝对位置编码的比较。</p></li><li><p><strong>RoPE原理</strong>：学习RoPE的设计思想：通过旋转矩阵来增强位置编码在模型中的表现，尤其是在处理长序列时如何避免传统位置编码的性能瓶颈。</p></li></ul></li></ul><p>4. <strong>QKV缓存（Query-Key-Value 缓存）</strong></p><ul><li><p><strong>目标</strong>：掌握QKV缓存技术，理解其如何加速自注意力计算，特别是在推理阶段。</p></li><li><p><strong>学习内容</strong>：</p><ul><li><p><strong>自注意力机制</strong>：回顾自注意力机制的工作原理，重点理解Query、Key和Value的计算方式。</p></li><li><p><strong>QKV缓存概念</strong>：学习QKV缓存的作用，即在推理阶段缓存先前层计算的Q、K、V值，避免每次重新计算，从而加速推理过程。</p></li></ul></li></ul>`,129)])])}const r=i(t,[["render",h]]),k=JSON.parse('{"path":"/LearningRoute/cet5kng4/","title":"基础内容概述","lang":"zh-CN","frontmatter":{"title":"基础内容概述","createTime":"2025/10/19 15:42:04","permalink":"/LearningRoute/cet5kng4/"},"readingTime":{"minutes":16.79,"words":5038},"git":{"createdTime":1760860007000,"updatedTime":1760860007000},"filePathRelative":"notes/LearningRoute/5.AI 方向/1.基础内容概述.md","headers":[]}');export{r as comp,k as data};
